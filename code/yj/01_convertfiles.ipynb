{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def read_anntation(xml_file: str):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    bounding_box_list = []\n",
    "\n",
    "    file_name = root.find('filename').text\n",
    "    for obj in root.iter('object'):\n",
    "\n",
    "        object_label = obj.find(\"name\").text\n",
    "        for box in obj.findall(\"bndbox\"):\n",
    "            x_min = int(box.find(\"xmin\").text)\n",
    "            y_min = int(box.find(\"ymin\").text)\n",
    "            x_max = int(box.find(\"xmax\").text)\n",
    "            y_max = int(box.find(\"ymax\").text)\n",
    "\n",
    "        bounding_box = [object_label, x_min, y_min, x_max, y_max]\n",
    "        bounding_box_list.append(bounding_box)\n",
    "\n",
    "    return bounding_box_list, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def read_train_dataset(dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    for file in listdir(dir):\n",
    "        if 'jpg' in file.lower() or 'png' in file.lower():\n",
    "            images.append(cv2.imread(dir + file, 1))\n",
    "            annotation_file = file.replace(file.split('.')[-1], 'xml')\n",
    "            bounding_box_list, file_name = read_anntation(dir + annotation_file)\n",
    "            annotations.append((bounding_box_list, annotation_file, file_name))\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting files\n  Downloading files-1.1.1.tar.gz (10 kB)\nBuilding wheels for collected packages: files\n  Building wheel for files (setup.py): started\n  Building wheel for files (setup.py): finished with status 'done'\n  Created wheel for files: filename=files-1.1.1-py3-none-any.whl size=3670 sha256=f591efe57a106bdfa13ced93ed79e2a26b2a8919d22429dc2e9e6532661b148e\n  Stored in directory: c:\\users\\luvu1\\appdata\\local\\pip\\cache\\wheels\\49\\93\\8d\\577f016b6575dbe61c8f2de6fec2a4a9c94eccb2bb3655cd50\nSuccessfully built files\nInstalling collected packages: files\nSuccessfully installed files-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from files import *\n",
    "from pascal_voc_writer import Writer\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "dir = 'C:/Users/luvu1/Documents/data_analysis/DeepLearning_Project/100_People_Multi-view_Tracking_Data (1)/data/Multi-view_tracking_indoor/00001_market/frames/xmlfile/'\n",
    "images, annotations = read_train_dataset(dir)\n",
    "\n",
    "for idx in range(len(images)):\n",
    "    image = images[idx]\n",
    "    boxes = annotations[idx][0]\n",
    "\n",
    "    ia_bounding_boxes = []\n",
    "    for box in boxes:\n",
    "        ia_bounding_boxes.append(ia.BoundingBox(x1=box[1], y1=box[2], x2=box[3], y2=box[4]))\n",
    "\n",
    "    bbs = ia.BoundingBoxesOnImage(ia_bounding_boxes, shape=image.shape)\n",
    "\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Multiply((1.2, 1.5)),\n",
    "        iaa.Affine(\n",
    "            translate_px={\"x\": 40, \"y\": 60},\n",
    "            scale=(0.5, 0.7),\n",
    "            rotate=45\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    seq_det = seq.to_deterministic()\n",
    "\n",
    "    image_aug = seq_det.augment_images([image])[0]\n",
    "    bbs_aug = seq_det.augment_bounding_boxes([bbs])[0]\n",
    "\n",
    "    new_image_file = dir + 'after_' + annotations[idx][2]\n",
    "    cv2.imwrite(new_image_file, image_aug)\n",
    "\n",
    "    h, w = np.shape(image_aug)[0:2]\n",
    "    voc_writer = Writer(new_image_file, w, h)\n",
    "\n",
    "    for i in range(len(bbs_aug.bounding_boxes)):\n",
    "        bb_box = bbs_aug.bounding_boxes[i]\n",
    "        voc_writer.addObject(boxes[i][0], int(bb_box.x1), int(bb_box.y1), int(bb_box.x2), int(bb_box.y2))\n",
    "\n",
    "    voc_writer.save(dir + 'after_' + annotations[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pascal-voc-writer\n",
      "  Downloading pascal_voc_writer-0.1.4-py2.py3-none-any.whl (4.0 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\luvu1\\anaconda3\\lib\\site-packages (from pascal-voc-writer) (2.11.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\luvu1\\anaconda3\\lib\\site-packages (from jinja2->pascal-voc-writer) (1.1.1)\n",
      "Installing collected packages: pascal-voc-writer\n",
      "Successfully installed pascal-voc-writer-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pascal-voc-writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "ia.seed(1)\n",
    "# imgaug uses matplotlib backend for displaying images\n",
    "%matplotlib inline\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa \n",
    "# imageio library will be used for image input/output\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "# this library is needed to read XML files for converting it into CSV\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will extract column data for our CSV file as pandas DataFrame\n",
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            try:\n",
    "                value = (root.find('filename').text,\n",
    "                         int(root.find('size')[0].text),\n",
    "                         int(root.find('size')[1].text),\n",
    "                         member[0].text,\n",
    "                         int(member[4][0].text),\n",
    "                         int(member[4][1].text),\n",
    "                         int(member[4][2].text),\n",
    "                         int(member[4][3].text)\n",
    "                         )\n",
    "                xml_list.append(value)\n",
    "            except:\n",
    "                pass\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "   \n",
    "# apply the function to convert all XML files in images/ folder into labels.csv\n",
    "labels_df = xml_to_csv('C:/Users/luvu1/Documents/data_analysis/DeepLearning_Project/xmlfile/')\n",
    "# labels_df.to_csv('labels.txt', index=False, header=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.to_csv('C:/Users/luvu1/Documents/data_analysis/DeepLearning_Project/xmlfile/labels.txt', index=False, header=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    filename  width  height   class  xmin  ymin  xmax  ymax\n",
       "0  01_01.jpg   1920    1080  person  1074     1  1174   197\n",
       "1  01_02.jpg   1920    1080  person  1074     2  1166   200\n",
       "2  01_03.jpg   1920    1080  person   977    24  1041   200\n",
       "3  01_04.jpg   1920    1080  person   839    80   937   306\n",
       "4  01_05.jpg   1920    1080  person   686   138   833   414"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01_01.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>1074</td>\n      <td>1</td>\n      <td>1174</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01_02.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>1074</td>\n      <td>2</td>\n      <td>1166</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01_03.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>977</td>\n      <td>24</td>\n      <td>1041</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01_04.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>839</td>\n      <td>80</td>\n      <td>937</td>\n      <td>306</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01_05.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>686</td>\n      <td>138</td>\n      <td>833</td>\n      <td>414</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = (labels_df['xmin'] + labels_df['xmax']) / 2\n",
    "labels_df['center_x'] = num / labels_df['width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = (labels_df['ymin'] + labels_df['ymax']) / 2\n",
    "labels_df['center_y'] = num / labels_df['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = (labels_df['xmax'] - labels_df['xmin'])\n",
    "labels_df['w'] = num / labels_df['width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    filename  width  height   class  xmin  ymin  xmax  ymax  center_x  \\\n",
       "0  01_01.jpg   1920    1080  person  1074     1  1174   197  0.585417   \n",
       "1  01_02.jpg   1920    1080  person  1074     2  1166   200  0.583333   \n",
       "2  01_03.jpg   1920    1080  person   977    24  1041   200  0.525521   \n",
       "3  01_04.jpg   1920    1080  person   839    80   937   306  0.462500   \n",
       "4  01_05.jpg   1920    1080  person   686   138   833   414  0.395573   \n",
       "\n",
       "   center_y         w         h  \n",
       "0  0.091667  0.052083  0.181481  \n",
       "1  0.093519  0.047917  0.183333  \n",
       "2  0.103704  0.033333  0.162963  \n",
       "3  0.178704  0.051042  0.209259  \n",
       "4  0.255556  0.076563  0.255556  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n      <th>center_x</th>\n      <th>center_y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01_01.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>1074</td>\n      <td>1</td>\n      <td>1174</td>\n      <td>197</td>\n      <td>0.585417</td>\n      <td>0.091667</td>\n      <td>0.052083</td>\n      <td>0.181481</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01_02.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>1074</td>\n      <td>2</td>\n      <td>1166</td>\n      <td>200</td>\n      <td>0.583333</td>\n      <td>0.093519</td>\n      <td>0.047917</td>\n      <td>0.183333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01_03.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>977</td>\n      <td>24</td>\n      <td>1041</td>\n      <td>200</td>\n      <td>0.525521</td>\n      <td>0.103704</td>\n      <td>0.033333</td>\n      <td>0.162963</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01_04.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>839</td>\n      <td>80</td>\n      <td>937</td>\n      <td>306</td>\n      <td>0.462500</td>\n      <td>0.178704</td>\n      <td>0.051042</td>\n      <td>0.209259</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01_05.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>person</td>\n      <td>686</td>\n      <td>138</td>\n      <td>833</td>\n      <td>414</td>\n      <td>0.395573</td>\n      <td>0.255556</td>\n      <td>0.076563</td>\n      <td>0.255556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "num = (labels_df['ymax'] - labels_df['ymin'])\n",
    "labels_df['h'] = num / labels_df['height']\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(labels_df)):\n",
    "  data = labels_df.iloc[idx]\n",
    "  filename = data['filename'].split('.')[0]\n",
    "  f = open('C:/Users/luvu1/Documents/data_analysis/DeepLearning_Project/100_People_Multi-view_Tracking_Data (1)/data/Multi-view_tracking_indoor/00001_market/frames/training/{}.txt'.format(filename), 'w')\n",
    "  wdata = str(\"0 {} {} {} {}\".format(data['center_x'], data['center_y'], data['w'], data['h']))\n",
    "  f.write(wdata)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "  data = labels_df.iloc[0]\n",
    "  f = open(\"new.txt\", 'w')\n",
    "  wdata = str(\"0 {} {} {} {}\".format(data['center_x'], data['center_y'], data['w'], data['h']))\n",
    "  f.write(wdata)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\luvu1\\Documents\\data_analysis\\DeepLearning_Project\\100_People_Multi-view_Tracking_Data (1)\\data\\Multi-view_tracking_indoor\\00001_market\\frames\\training"
   ]
  }
 ]
}